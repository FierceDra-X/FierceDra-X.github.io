![Авто](https://demotivation.ru/wp-content/uploads/2020/10/c3c70dfaaf031be7f2b2cac82ed87ce8.jpg)

# **Проект прогнозирования стоимости автомобилей по его характеристикам. Module 5 SkillFactory**
__________________________________________________________________________________________________________________

**Проект состоит из трех частей:**
> - Часть 1 проекта - сбор первичных данных об автомобилях с сайта [auto.ru](https://auto.ru/). Код Части 1 находится в файле auto_parsing.ipynb;
> - Часть 2 проекта - обработка первичных данных, собранных с сайта [auto.ru](https://auto.ru/) до формата, пригодного к feature engineering и моделированию. Код Части 2 находится в файле data_auto_processing.ipynb;
> - Часть 3 проекта - feature engineering и создание модели прогноза стоимости б-у автомобилей. Код Части 3 находится в файле auto_ml_module_5.ipynb;

# Содержание <a name="вверх"></a>

- [1. Сбор первичных данных](#сбор)
- [2. Предобработка данных](#предобработка)
- [3. Feature engineering](#fe)
- [4. Моделирование](#модель)

## **1. Сбор первичных данных** <a name="сбор"></a>

В этом проекте первичные данные по б-у автомобилям для обучения модели отсутствовали. Есть только данные тестового сета test.csv на сайте [kaggle_competition](https://www.kaggle.com/c/sf-dst-car-price-prediction/data?select=test.csv), предназначенные для прогнозирвания цены авто и представления прогноза на оценку в ```kaggle``` соревнование. По этой причине сбор данных необходимо было сделать c нуля.
Данные собирались с сайта [auto.ru](https://auto.ru/). Код сбора данных можно посмотреть в файле [auto_parsing.ipynb](https://github.com/FierceDra/FierceDra-X.github.io/blob/main/module_5/auto_parsing.ipynb).
```
Анализ файла с test.csv показал, что прогнозирование необходимо строить по 12-ти брендам авто:
AUDI, BMW, MERCEDES, VOLVO, TOYOTA, MITSUBISHI, SKODA, LEXUS, INFINITI, VOLKSWAGEN, NISSAN, HONDA
Сбор данных был сделан по этим брендам.
```

В коде сбора данных выполнялись следующие задачи с помощью библиотек request и bs4:
- [ ] Для каждого бренда и модели авто в цикле формировался список urls страниц по количеству доступных на сайте;
- [ ] Во втором цикле с помощью request и BeautifulSoup по идентифицированному на сайте тэгу и клссу собирались в единый список ссылок на отдельные авто;
- [ ] Перед третьим циклом составлялись списки тэгов и классов, по которым можно найти данные по авто, соответствующие основноым данным тестового сета;
- [ ] В третьем цикле делался проход по всем собранным ссылкам на отдельные авто и собирались данные в единый массив;
- [ ] Далее массив сохранялся в датафрейме и копировался в буферный файл [буферный файл сырых данных (пример)](https://github.com/FierceDra/FierceDra-X.github.io/blob/main/module_5/data_auto_f.csv);
- [ ] На формировании буферного файла с сырыми данными по авто код заканчивается, а буферный файл далее используется во второй части файла предобработки данных.

:arrow_up: [Содержание](#вверх)

## **2. Предобработка данных** <a name="предобработка"></a>

Собранные на сайте данные находятся в очень сыром виде. Формат данных полностью текстовый. Текст данных сильно засорен лишними фразами и символами. В этой ситуации ключевой библиотекой для вычленения из мусора необходимых слов и цифр была библиотека re. Код предобработки данных можно посмотреть в файле [файл предобработки](https://github.com/FierceDra/FierceDra-X.github.io/blob/main/module_5/data_auto_processing.ipynb).

В коде сбора данных выполнялись следующие задачи с помощью библиотек re, pandas и numpy:
- [ ] из буферного файла, полученного в Части 1 проекта, данные формировали датасет для работы с данными;
- [ ] всего 14 признаков ```'bodytype', 'brand', 'mileage', 'color', 'engine', 'complectation',
       'tax', 'transmission', 'drive', 'wheel', 'owners', 'customs', 'pts',
       'year', 'price'```, каждый требует предобработки;
- [ ] далее в коде идет проход по каждому признаку и с помощью функций осуществляется очистка данных и преобразование их к нужному формату (int, float);
- [ ] из признака ```'engine'``` формируются три признака, соответствующие данным в тестовом сете (мощность, объем и тип топлива двигателя);
- [ ] далее очищенный датасет конкатенируется с ранее очищенными данными, пополняя общий датасет очищенных данных данными по новой модели;
- [ ] на последнем шаге пополненный очищенными датасет перезаписывается в файл, содержащий чистые данные [train датасет](https://github.com/FierceDra/FierceDra-X.github.io/blob/main/module_5/data_auto_processed_FINAL_3.csv);
- [ ] файл с читыми данными далее будет использоваться в feature engineering и моделировании в Части 3 проекта.

:arrow_up: [Содержание](#вверх)

## **3. Feature engineering** <a name="fe"></a>

Код Части 3 проекта можно посмотреть в файле [файл моделирования](https://github.com/FierceDra/FierceDra-X.github.io/blob/main/module_5/data_auto_processed_FINAL_3.csv).

В коде Части 3 выполнялись следующие задачи Feature engineering:
- [ ] для train датасета использовался файл с собранными и предобработанными данными, полученный в Части 2 проекта. Этот файл, тестовый дата сет с kaggle competition и файл формат sample_submission загружались в датасет;
- [ ] train и test датафреймы дополнительно предобрабатывались для приведения формата, структуры данных, названий признаков в единую и идентичную структуру;
- [ ] после этого  train и test датафреймы объединялись, а единый датасет попадал далее в блок feature engineering;
- [ ] необходимо отметить, что тестового файл нет в этом репозитории, он имеет вес более 100 Мб. Этот файл можно взять по ссылке [kaggle_competition](https://www.kaggle.com/c/sf-dst-car-price-prediction/data?select=test.csv);
- [ ] таргетом у нас является цена б-у автомобилей. Однако судя по парсинг времени test датасета он собирался год назад. Цены выросли сильно на автомобили за год. По этой причине таргет был скорректирован на рост цен;
- [ ] на каждом цикле сбора свежих данных следилось за тем, чтобы распределение собранных данных и тестовых данных по брендам примерно покрывали друг друга, так, чтобы структура данных test и train сетов были похожи;
- [ ] в ходе сбора данных, попались данные с признаком "tax", которого нет в test сете. С помощью алгоритма KNeighbors  в test сете была сформирована такая колонка данных;
- [ ] из сильно коррелирующих данных с помощью метода выделения главнойткомпоненты формировался новый признак;
- [ ] по категориальным данных формировались численные категории, либо функцией, либо LabelEncoder, к бинарным данным применялось get_dummies;
- [ ] ряд прзнаков логарифмировался или брался корень для приведения данных в похожие масштабы;
- [ ] Также были составлены дополнительные признаки путем перемножения коррелирующих признаков;
- [ ] Итого получилось 25 признаков (24 без sample), однако в дальнейшем сам признак tax был удален (без него рпогноз был лучше), но он использовался в формировании нелинейного признака;

:arrow_up: [Содержание](#вверх)

## **4. Моделирование** <a name="модель"></a>
Блок построения модели также содержится в Части 3 проекта и его можно посмотреть в файле [файл моделирования](https://github.com/FierceDra/FierceDra-X.github.io/blob/main/module_5/data_auto_processed_FINAL_3.csv).

В коде Части 3 выполнялись следующие задачи меодлирования:
- [ ] для тестирования корректности сбора данных было опробовано наивное моделирование линейной регрессией, точность была на уровне 22%;
- [ ] Далее в пайплайне тестировались и сравнивались ряд дургих моделей с дефолтными параметрами, из которых наилучший результат показала модель ExtraTreesRegressor;
- [ ] кроме того, контролировался прогресс обучения через learning curve в зависимости от объема собранных данных. Примерно на 60 000 данных прогресс сильно замедлился и значительно не улучшался;
- [ ] дефолтные модели были ранжированы по точности прогноза;
- [ ] для лучших дефолтных моделей были подобраны оптимальные гиперпараметры;
- [ ] Лучшая модель ExtraTreesRegressor с лушими отобраными гиперпараметрами показала точность на уровне 15,35% МАРЕ;
- [ ] Следующим шагом была попытка улучшить результат ExtraTreesRegressor стекингом моделей. В стекинге подбирали анасамбль из моделей разной природы (регрессия, соседи, деревья и градиентный бустинг);
- [ ] проведено моделирование ансамблем моделей в стекинге, что показало улучшение, дальнейшее небольшое улучшение удалось получить сделав из метапризнаков дополнительные нелинейные метапризнаки путем перемножения метапризнаков. Итоговый результат улучшить удалось до уровня 14,35%

:arrow_up: [Содержание](#вверх)
___________

